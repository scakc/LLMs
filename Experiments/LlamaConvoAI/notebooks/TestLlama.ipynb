{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "621ca08e-a420-4a74-8c86-50796f5c4371",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from llama_cpp import Llama"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ea8dfb4d-c672-4ae0-ac4c-e1d1da30bf57",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Volume in drive C is Local Disk\n",
      " Volume Serial Number is 48D2-8B33\n",
      "\n",
      " Directory of C:\\Users\\kumarabh\\Downloads\\Work\\Experiments\\LLMs\\Models\\Llama7b\n",
      "\n",
      "18-08-2023  16:22    <DIR>          .\n",
      "18-08-2023  15:22    <DIR>          ..\n",
      "18-08-2023  16:05                27 config.json\n",
      "18-08-2023  16:05             1,477 gitattributes.txt\n",
      "18-08-2023  16:22     2,802,295,424 llama-7b.ggmlv3.q2_K.bin\n",
      "18-08-2023  16:17     7,160,799,872 llama-7b.ggmlv3.q8_0.bin\n",
      "18-08-2023  16:05            10,475 README.md\n",
      "               5 File(s)  9,963,107,275 bytes\n",
      "               2 Dir(s)  763,692,445,696 bytes free\n"
     ]
    }
   ],
   "source": [
    "!dir .\\..\\..\\..\\Models\\Llama7b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2ad1f9b8-2eab-4f41-bb71-fc2a5840d8c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "AVX = 1 | AVX2 = 1 | AVX512 = 0 | AVX512_VBMI = 0 | AVX512_VNNI = 0 | FMA = 1 | NEON = 0 | ARM_FMA = 0 | F16C = 1 | FP16_VA = 0 | WASM_SIMD = 0 | BLAS = 0 | SSE3 = 1 | VSX = 0 | \n"
     ]
    }
   ],
   "source": [
    "llm = Llama(model_path=\"../../../Models/Llama7b/llama-7b.ggmlv3.q8_0.bin\", n_ctx=1024)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5a4c9d78-b05f-44f9-b8e6-52015a8eed15",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Make a sentence out of all words:\n",
      "\n",
      "\n",
      "\n",
      "Words:\n",
      "Rahul\n",
      "Apple\n",
      "Monkey\n",
      "\n",
      "Generated Sentence:\n",
      "\n"
     ]
    }
   ],
   "source": [
    "header_prompt = \"\"\"\n",
    "Make a sentence out of all words:\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "queries = [\"Rahul\", \"Apple\", \"Monkey\"]\n",
    "\n",
    "def get_prompt(header_prompt, queries):\n",
    "    return header_prompt + '\\n\\nWords:\\n' + '\\n'.join([\"\" + query for query in queries])  + '\\n\\nGenerated Sentence:\\n'\n",
    "\n",
    "input_text = get_prompt(header_prompt, queries)\n",
    "print(input_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4dc0f429-7f2a-481b-9243-8baf6f74b065",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_queries = queries[:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "de6e5bba-c055-43a0-ad0e-fff6b23597db",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Make a sentence out of all words:\n",
      "\n",
      "\n",
      "\n",
      "Words:\n",
      "Apple\n",
      "Rahul\n",
      "Monkey\n",
      "\n",
      "Generated Sentence:\n",
      "An apple a day keeps the doctor away.\n"
     ]
    }
   ],
   "source": [
    "temp_queries = list(np.random.choice(new_queries, 3, replace = False))\n",
    "input_text = get_prompt(header_prompt, temp_queries)\n",
    "output = llm(input_text, max_tokens=1000, stop=[\"\\n\"], echo=True)\n",
    "print(output['choices'][0]['text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4187d74e-5888-4ae5-8259-2f8fe6936c73",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
